{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import transforms as tt\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "\n",
    "\n",
    "from ccb.experiment.experiment import Job, get_model_generator\n",
    "from ccb.torch_toolbox.dataset import DataModule\n",
    "from ccb.dataset_converters.inspect_tools import float_image_to_uint8, overlay_label\n",
    "\n",
    "from ruamel.yaml import YAML\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import tempfile\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ccb import io\n",
    "from ccb.io.dataset import Band\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = \"/mnt/home/climate-change-benchmark/ccb/configs/classification_config.yaml\"\n",
    "task_specs_path = \"/mnt/data/cc_benchmark/classification_v0.7/eurosat/task_specs.pkl\"\n",
    "task = \"classification\" if \"classification\" in task_specs_path else \"segmentation\"\n",
    "\n",
    "with Path(config_file_path).open() as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config[\"model\"][\"model_generator_module_name\"] = \"ccb.torch_toolbox.model_generators.timm_generator\"\n",
    "config[\"model\"][\"backbone\"] = \"resnet18\"\n",
    "config[\"model\"][\"encoder_type\"] = \"resnet18\"\n",
    "config[\"model\"][\"decoder_type\"] = \"Unet\"\n",
    "\n",
    "config[\"model\"][\"desired_input_size\"] = 224\n",
    "config[\"model\"][\"batch_size\"] = 16\n",
    "config[\"experiment\"][\"benchmark_dir\"] = str(Path(task_specs_path).parents[1])\n",
    "\n",
    "\n",
    "with open(task_specs_path, \"rb\") as fd:\n",
    "    task_specs = pickle.load(fd)\n",
    "\n",
    "num_samples_to_viz = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create temporary job directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fill experiment directory\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "temp_dir_path = temp_dir.name\n",
    "\n",
    "job_dir = Path(temp_dir_path) / task_specs.dataset_name\n",
    "job = Job(job_dir)\n",
    "job.save_config(config)\n",
    "job.save_task_specs(task_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataModule and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = get_model_generator(config[\"model\"][\"model_generator_module_name\"])\n",
    "\n",
    "model = model_gen.generate_model(task_specs=job.task_specs, config=config)\n",
    "\n",
    "train_ds = task_specs.get_dataset(\n",
    "    split=\"train\",\n",
    "    partition_name=config[\"experiment\"][\"partition_name\"],\n",
    "    band_names=config[\"dataset\"][\"band_names\"],\n",
    "    format=config[\"dataset\"][\"format\"],\n",
    "    benchmark_dir=Path(task_specs_path).parents[1],\n",
    ")\n",
    "\n",
    "eval_ds = task_specs.get_dataset(\n",
    "    split=\"valid\",\n",
    "    partition_name=config[\"experiment\"][\"partition_name\"],\n",
    "    band_names=config[\"dataset\"][\"band_names\"],\n",
    "    format=config[\"dataset\"][\"format\"],\n",
    "    benchmark_dir=Path(task_specs_path).parents[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a transform function that you would like to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_transform_function_classification(task_specs, config, train=True):\n",
    "    mean, std = task_specs.get_dataset(\n",
    "            split=\"train\",\n",
    "            format=config[\"dataset\"][\"format\"],\n",
    "            band_names=tuple(config[\"dataset\"][\"band_names\"]),\n",
    "            benchmark_dir=config[\"experiment\"][\"benchmark_dir\"],\n",
    "            partition_name=config[\"experiment\"][\"partition_name\"],\n",
    "        ).normalization_stats()\n",
    "\n",
    "    desired_input_size = config[\"model\"][\"default_input_size\"][1]\n",
    "\n",
    "    t = []\n",
    "    t.append(tt.ToTensor())\n",
    "    t.append(tt.Normalize(mean=mean, std=std))\n",
    "    if train:\n",
    "        t.append(tt.RandomHorizontalFlip())\n",
    "\n",
    "    t.append(tt.Resize((desired_input_size, desired_input_size)))\n",
    "    transform_comp = tt.Compose(t)\n",
    "\n",
    "    def transform(sample):\n",
    "        x: \"np.typing.NDArray[np.float_]\" = sample.pack_to_3d(band_names=config[\"dataset\"][\"band_names\"])[0].astype(\n",
    "            \"float32\"\n",
    "        )\n",
    "        print(\"before\")\n",
    "        print(x.shape)\n",
    "        print((x[:,:, 0].mean(), x[:,:, 0].std()), (x[:,:,1].mean(), x[:,:, 1].std()), (x[:,:, 2].mean(), x[:,:, 2].std()))\n",
    "        \n",
    "        x = transform_comp(x)\n",
    "\n",
    "        print(\"after\")\n",
    "        print(x.shape)\n",
    "        print((x[0,:,:].mean().item(), x[0,:,:].std().item()), (x[1,:,:].mean().item(), x[1,:,:].std().item()), (x[2,:,:].mean().item(), x[2,:,:].std().item()))\n",
    "\n",
    "        \n",
    "        assert x.shape[1] in [224, 256]\n",
    "        return {\"input\": x, \"label\": sample.label}\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation Transform Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_transform_function_segmentation(task_specs, config, train=True):\n",
    "    \n",
    "    c, h, w = config[\"model\"][\"input_size\"]\n",
    "    patch_h, patch_w = task_specs.patch_size\n",
    "    if h != w or patch_h != patch_w:\n",
    "        raise (RuntimeError(\"Only square patches are supported in this version\"))\n",
    "    h32 = w32 = int(32 * (h // 32))  # make input res multiple of 32\n",
    "\n",
    "    mean, std = task_specs.get_dataset(\n",
    "        split=\"train\",\n",
    "        format=config[\"dataset\"][\"format\"],\n",
    "        band_names=tuple(config[\"dataset\"][\"band_names\"]),\n",
    "        benchmark_dir=config[\"experiment\"][\"benchmark_dir\"],\n",
    "        partition_name=config[\"experiment\"][\"partition_name\"],\n",
    "    ).normalization_stats()\n",
    "    \n",
    "    band_names = config[\"dataset\"][\"band_names\"]\n",
    "\n",
    "    t = []\n",
    "    if h < patch_h:\n",
    "        t.append(A.SmallestMaxSize(max_size=h))\n",
    "    t.append(A.RandomCrop(h32, w32))\n",
    "    if train:\n",
    "        t.append(A.RandomRotate90(0.5))\n",
    "        t.append(A.Flip())\n",
    "    t.append(A.Normalize(mean=mean, std=std))\n",
    "    t.append(ToTensorV2())\n",
    "    t_comp = A.Compose(t)\n",
    "\n",
    "    def transform(sample):\n",
    "        x = sample.pack_to_3d(band_names=band_names)[0].astype(\"float32\")\n",
    "\n",
    "        if isinstance(sample.label, Band):\n",
    "            x, y = x, sample.label.data.astype(\"float32\")\n",
    "            print(\"before\")\n",
    "            print(x.shape)\n",
    "            print((x[:,:, 0].mean(), x[:,:, 0].std()), (x[:,:,1].mean(), x[:,:, 1].std()), (x[:,:, 2].mean(), x[:,:, 2].std()))\n",
    "            transformed = t_comp(image=x, mask=y)\n",
    "            print(\"after\")\n",
    "            a_img = transformed[\"image\"]\n",
    "            print(a_img.shape)\n",
    "            print((a_img[0,:,:].mean().item(), a_img[0,:,:].std().item()), (a_img[1,:,:].mean().item(), a_img[1,:,:].std().item()), (a_img[2,:,:].mean().item(), a_img[2,:,:].std().item()))\n",
    "\n",
    "        return {\"input\": transformed[\"image\"], \"label\": transformed[\"mask\"].long()}\n",
    "\n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == \"classification\":\n",
    "    check_train_transform = check_transform_function_classification(task_specs, config, train=True)\n",
    "    check_eval_transform = check_transform_function_classification(task_specs, config, train=False)\n",
    "elif task == \"segmentation\":\n",
    "    check_train_transform = check_transform_function_segmentation(task_specs, config, train=True)\n",
    "    check_eval_transform = check_transform_function_segmentation(task_specs, config, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a batch from a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_batch(ds, num_samples = num_samples_to_viz):\n",
    "    before_transform = []\n",
    "    after_transform = []\n",
    "    for i in range(num_samples_to_viz):\n",
    "        rand_idx = random.randint(0, len(ds))\n",
    "        sample = ds[rand_idx]\n",
    "        sample_array = sample.pack_to_3d(band_names=config[\"dataset\"][\"band_names\"])[0].astype(\"float32\")\n",
    "        before_transform.append({\"input\": sample_array, \"label\": sample.label})\n",
    "        transformed_sample = check_train_transform(sample)\n",
    "        after_transform.append(transformed_sample)\n",
    "\n",
    "    return before_transform, after_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciton to visualize transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classification(before, after):\n",
    "    before_for_viz = float_image_to_uint8([b[\"input\"] for b in before])\n",
    "    after_for_viz = float_image_to_uint8([a[\"input\"].permute(1, 2, 0).numpy() for a in after])\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=2, nrows=len(before), figsize=(20, 60))\n",
    "    for idx, (b, a, b_z, a_z) in enumerate(zip(before, after, before_for_viz, after_for_viz)):\n",
    "        # visualize before\n",
    "        axs[idx, 0].imshow(b_z)\n",
    "        axs[idx, 0].axis(\"off\")\n",
    "\n",
    "        if idx == 0:\n",
    "            axs[idx, 0].set_title(\"Original\")\n",
    "\n",
    "        # visualize table that shows transformation values\n",
    "        b_img = b[\"input\"]\n",
    "        a_img = a[\"input\"]\n",
    "        data = {\n",
    "            'image_size': [b_img.shape[0], a_img.shape[2]], \n",
    "            'max_px': [b_img.max(), a_img.max().item()], \n",
    "            'min_px': [b_img.min(), a_img.min().item()],\n",
    "            'mean_px': [b_img.mean(), a_img.mean().item()],\n",
    "            'std_px': [b_img.std(), a_img.std().item()]\n",
    "        }\n",
    "        df = pd.DataFrame.from_dict(data, orient='index', columns=[\"before\", \"after\"])\n",
    "\n",
    "        # axs[idx, 1].table(cellText=df.values, colLabels=df.columns, rowLabels=df.index, loc='center')\n",
    "        # axs[idx, 1].axis(\"off\")\n",
    "        \n",
    "        # visualize after\n",
    "        axs[idx, 1].imshow(a_z)\n",
    "        if idx == 0:\n",
    "            axs[idx, 1].set_title(\"After transform\")\n",
    "        # TODO convert classification numeric label into text label\n",
    "        axs[idx, 1].axis(\"off\")\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    wspace = 0   # the amount of width reserved for blank space between subplots\n",
    "    plt.subplots_adjust(wspace=wspace)\n",
    "    plt.show()\n",
    "\n",
    "def color_list(n_classes, background_id=0, background_color=(0, 0, 0)):\n",
    "    colors = cm.hsv(np.linspace(0, 1, n_classes + 1))\n",
    "    colors = colors[:, :-1]  # drop the last column since it corresponds to alpha channel.\n",
    "    colors = colors[:-1]  # drop the last color since it's almost the same as the 1st color.\n",
    "    colors[background_id, :] = background_color\n",
    "    return colors\n",
    "\n",
    "def visualize_segmentation(before, after):\n",
    "    before_imgs = float_image_to_uint8([b[\"input\"] for b in before])\n",
    "    before_labels = [b[\"label\"] for b in before]\n",
    "    before_for_viz = [{\"input\": img, \"label\": label} for img, label in zip(before_imgs, before_labels)]\n",
    "\n",
    "    after_imgs = float_image_to_uint8([a[\"input\"].permute(1, 2,0).numpy() for a in after])\n",
    "    after_labels = [a[\"label\"].numpy() for a in after]\n",
    "    after_for_viz = [{\"input\": img, \"label\": label} for img, label in zip(after_imgs, after_labels)]\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=len(before), figsize=(20, 60))\n",
    "    for idx, (b, a, b_z, a_z) in enumerate(zip(before, after, before_for_viz, after_for_viz)):\n",
    "        # visualize before\n",
    "        img = overlay_label(b_z[\"input\"], b_z[\"label\"], label_patch_size=None, opacity=0.5).astype(int)\n",
    "        axs[idx, 0].imshow(img)\n",
    "        axs[idx, 0].axis(\"off\")\n",
    "        if idx == 0:\n",
    "            axs[idx, 0].set_title(\"Before transform\")\n",
    "\n",
    "        # visualize table that shows transformation values\n",
    "        b_img = b[\"input\"]\n",
    "        a_img = a[\"input\"]\n",
    "        data = {\n",
    "            'image_size': [b_img.shape[0], a_img.shape[2]], \n",
    "            'max_px': [b_img.max(), a_img.max().item()], \n",
    "            'min_px': [b_img.min(), a_img.min().item()],\n",
    "            'mean_px': [b_img.mean(), a_img.mean().item()],\n",
    "            'std_px': [b_img.std(), a_img.std().item()]\n",
    "        }\n",
    "        df = pd.DataFrame.from_dict(data, orient='index', columns=[\"before\", \"after\"])\n",
    "\n",
    "        axs[idx, 1].table(cellText=df.values, colLabels=df.columns, rowLabels=df.index, loc='center')\n",
    "        axs[idx, 1].axis(\"off\")\n",
    "\n",
    "        # visualize after\n",
    "        img = torch.from_numpy(a_z[\"input\"]).permute(2, 0, 1)\n",
    "\n",
    "        label = torch.from_numpy(a_z[\"label\"])\n",
    "        colors = color_list(task_specs.label_type.n_classes)\n",
    "        \n",
    "        one_hot_label = torch.nn.functional.one_hot(label, num_classes=task_specs.label_type.n_classes).permute(2, 0, 1).bool()\n",
    "        \n",
    "        img = draw_segmentation_masks(img, one_hot_label, alpha=0.5)\n",
    "        \n",
    "        # axs[idx, 2].imshow(img.permute(1, 2, 0).numpy())\n",
    "        axs[idx, 2].imshow(a_z[\"input\"])\n",
    "        axs[idx, 2].axis(\"off\")\n",
    "        if idx == 0:\n",
    "            axs[idx, 2].set_title(\"After transform\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_transforms(before, after, task):\n",
    "    assert len(before) == len(after), \"Each input needs transformed output.\"\n",
    "    if task == \"classification\":\n",
    "        visualize_classification(before, after)\n",
    "    elif task == \"segmentation\":\n",
    "        visualize_segmentation(before, after)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid task, use 'classification' or 'segmentation'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_before, train_after = collect_batch(train_ds)\n",
    "visualize_transforms(train_before, train_after, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ccbEnv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50fb5aad75a1e334b0049d17a28c535a225b27a7c5ec5d2eea92f7c0e9e2da82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
