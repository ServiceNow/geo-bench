experiment:
  generate_experiment_dir: /mnt/data/experiments/nils/partition_sweeps_classification
  experiment_name: 0.01x_train # prefix
  experiment_type: sweep # standard, seeded_runs, sweep
  benchmark_dir: /mnt/data/cc_benchmark/classification_v0.5
  partition_name: 0.01x_train
model:
  model_generator_module_name: ccb.torch_toolbox.model_generators.timm_generator
  head_type: linear # classification
  loss_type: crossentropy
  new_channel_init_method: random
dataset:
  band_names: ["red", "green", "blue"]
  format: hdf5
dataloader:
  num_workers: 4
wandb:
  project: ccb # wandb project name
  entity: climate-benchmark # user or team entity that hosts a project
  sweep:
    sweep_config_path: /mnt/home/climate-change-benchmark/ccb/torch_toolbox/wandb/hparams_classification_resnet18.yaml # or maybe define the entire sweep here?
    num_agents: 4 # how many agents participate in sweep, one agent usually corresponds to one gpu
    num_trials_per_agent: 3 # how many hparam trials each agent should execute, num_agents x num_trials_per_agent corresponds to total number of trials executed by sweep
pl: # all flags for pytorch lightning Trainer module, see https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
  gpus: 1
  accelerator: gpu
  max_epochs: 500
  max_steps: -1
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  val_check_interval: 1.0
  deterministic: False
  log_every_n_steps: 10
  enable_progress_bar: False